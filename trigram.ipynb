{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da1b9fb8-7742-4a6c-b3d4-afa3d9439f3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([ 1,  1,  2,  1, 14,  0,  1,  1,  2,  1]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "words = open(\"60knames.csv\",'r').read().splitlines()[1:] # col name removed\n",
    "words = [word for word in words if not any(char in word for char in ['/','\"',',','-',\".\",\"/\",\";\",'±','Ã'])]\n",
    "\n",
    "# words = open(\"names.txt\",'r').read().splitlines()\n",
    "inp = []\n",
    "out = []\n",
    "\n",
    "all_char = sorted(set(\".\".join(words)))\n",
    "stoi = {ch:i for i,ch in enumerate(all_char)}\n",
    "itos = {v:k for k,v in stoi.items()}\n",
    "\n",
    "clen = 2\n",
    "for w in words:\n",
    "    context = '.' * clen\n",
    "    w =  w + '.'\n",
    "    for cur_ch in w:\n",
    "        cur_inp = [stoi[ch] for ch in context]\n",
    "        cur_inp[-1] += 27\n",
    "        inp.append(cur_inp)\n",
    "        out.append(stoi[cur_ch])\n",
    "        context = context[1:] + cur_ch\n",
    "    \n",
    "inp_tri = math.ceil(0.8*len(inp))\n",
    "inp_devi = math.ceil(0.9*len(inp))\n",
    "inp_tr = torch.tensor(inp[0:inp_tri])\n",
    "out_tr = torch.tensor(out[0:inp_tri])\n",
    "inp_dev =torch.tensor(inp[inp_tri:inp_devi])\n",
    "out_dev =torch.tensor(out[inp_tri:inp_devi])\n",
    "inp_tst =torch.tensor(inp[inp_devi:])\n",
    "out_tst =torch.tensor(out[inp_devi:])\n",
    "\n",
    "inp_tr  = F.one_hot(inp_tr,num_classes = 54).float()\n",
    "inp_tr = inp_tr.sum(dim=1)\n",
    "\n",
    "inp_tr[:10] ,out_tr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "746007e9-1387-48db-a6f1-d822a882c255",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(16)\n",
    "W = torch.randn((54,27),requires_grad = True,generator = g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937eb4f1-b398-4849-af56-c17f4a287164",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 2.2171647548675537 iter = 0\n",
      "loss = 2.217155933380127 iter = 1\n",
      "loss = 2.217146873474121 iter = 2\n",
      "loss = 2.2171378135681152 iter = 3\n",
      "loss = 2.2171289920806885 iter = 4\n",
      "loss = 2.2171196937561035 iter = 5\n",
      "loss = 2.217111110687256 iter = 6\n",
      "loss = 2.21710205078125 iter = 7\n",
      "loss = 2.217092752456665 iter = 8\n",
      "loss = 2.217083692550659 iter = 9\n",
      "loss = 2.2170748710632324 iter = 10\n",
      "loss = 2.2170660495758057 iter = 11\n",
      "loss = 2.2170569896698 iter = 12\n",
      "loss = 2.217048168182373 iter = 13\n",
      "loss = 2.217039108276367 iter = 14\n",
      "loss = 2.2170300483703613 iter = 15\n",
      "loss = 2.2170212268829346 iter = 16\n",
      "loss = 2.2170121669769287 iter = 17\n",
      "loss = 2.217003345489502 iter = 18\n",
      "loss = 2.216994047164917 iter = 19\n",
      "loss = 2.2169852256774902 iter = 20\n",
      "loss = 2.2169764041900635 iter = 21\n",
      "loss = 2.2169673442840576 iter = 22\n",
      "loss = 2.216958522796631 iter = 23\n",
      "loss = 2.216949462890625 iter = 24\n",
      "loss = 2.216940402984619 iter = 25\n",
      "loss = 2.2169315814971924 iter = 26\n",
      "loss = 2.2169225215911865 iter = 27\n",
      "loss = 2.2169134616851807 iter = 28\n",
      "loss = 2.216904878616333 iter = 29\n",
      "loss = 2.216895818710327 iter = 30\n",
      "loss = 2.2168867588043213 iter = 31\n",
      "loss = 2.2168776988983154 iter = 32\n",
      "loss = 2.2168691158294678 iter = 33\n",
      "loss = 2.216859817504883 iter = 34\n",
      "loss = 2.216850996017456 iter = 35\n",
      "loss = 2.2168421745300293 iter = 36\n",
      "loss = 2.2168331146240234 iter = 37\n",
      "loss = 2.2168242931365967 iter = 38\n",
      "loss = 2.216815233230591 iter = 39\n",
      "loss = 2.216806411743164 iter = 40\n",
      "loss = 2.2167978286743164 iter = 41\n",
      "loss = 2.2167885303497314 iter = 42\n",
      "loss = 2.2167794704437256 iter = 43\n",
      "loss = 2.216770648956299 iter = 44\n",
      "loss = 2.216761589050293 iter = 45\n",
      "loss = 2.216752767562866 iter = 46\n",
      "loss = 2.2167439460754395 iter = 47\n",
      "loss = 2.2167348861694336 iter = 48\n",
      "loss = 2.216726064682007 iter = 49\n",
      "loss = 2.216717004776001 iter = 50\n",
      "loss = 2.216707944869995 iter = 51\n",
      "loss = 2.2166993618011475 iter = 52\n",
      "loss = 2.2166903018951416 iter = 53\n",
      "loss = 2.216681480407715 iter = 54\n",
      "loss = 2.216672658920288 iter = 55\n",
      "loss = 2.2166635990142822 iter = 56\n",
      "loss = 2.2166545391082764 iter = 57\n",
      "loss = 2.2166457176208496 iter = 58\n",
      "loss = 2.2166366577148438 iter = 59\n",
      "loss = 2.216627836227417 iter = 60\n",
      "loss = 2.2166190147399902 iter = 61\n",
      "loss = 2.2166101932525635 iter = 62\n",
      "loss = 2.2166011333465576 iter = 63\n",
      "loss = 2.2165920734405518 iter = 64\n",
      "loss = 2.216583490371704 iter = 65\n",
      "loss = 2.216574192047119 iter = 66\n",
      "loss = 2.2165656089782715 iter = 67\n",
      "loss = 2.2165567874908447 iter = 68\n",
      "loss = 2.216547966003418 iter = 69\n",
      "loss = 2.216538906097412 iter = 70\n",
      "loss = 2.2165300846099854 iter = 71\n",
      "loss = 2.2165207862854004 iter = 72\n",
      "loss = 2.2165122032165527 iter = 73\n",
      "loss = 2.216503381729126 iter = 74\n",
      "loss = 2.216494560241699 iter = 75\n",
      "loss = 2.2164855003356934 iter = 76\n",
      "loss = 2.2164766788482666 iter = 77\n",
      "loss = 2.21646785736084 iter = 78\n",
      "loss = 2.216458797454834 iter = 79\n",
      "loss = 2.2164499759674072 iter = 80\n",
      "loss = 2.2164413928985596 iter = 81\n",
      "loss = 2.2164320945739746 iter = 82\n",
      "loss = 2.216423511505127 iter = 83\n",
      "loss = 2.216414451599121 iter = 84\n",
      "loss = 2.2164058685302734 iter = 85\n",
      "loss = 2.2163968086242676 iter = 86\n",
      "loss = 2.216387987136841 iter = 87\n",
      "loss = 2.216379165649414 iter = 88\n",
      "loss = 2.216370105743408 iter = 89\n",
      "loss = 2.2163615226745605 iter = 90\n",
      "loss = 2.2163524627685547 iter = 91\n",
      "loss = 2.216343641281128 iter = 92\n",
      "loss = 2.2163350582122803 iter = 93\n",
      "loss = 2.2163259983062744 iter = 94\n",
      "loss = 2.2163169384002686 iter = 95\n",
      "loss = 2.216308116912842 iter = 96\n",
      "loss = 2.216299295425415 iter = 97\n",
      "loss = 2.2162904739379883 iter = 98\n",
      "loss = 2.2162816524505615 iter = 99\n",
      "loss = 2.2162728309631348 iter = 100\n",
      "loss = 2.216263771057129 iter = 101\n",
      "loss = 2.216254949569702 iter = 102\n",
      "loss = 2.2162463665008545 iter = 103\n",
      "loss = 2.2162375450134277 iter = 104\n",
      "loss = 2.216228485107422 iter = 105\n",
      "loss = 2.216219902038574 iter = 106\n",
      "loss = 2.2162108421325684 iter = 107\n",
      "loss = 2.2162022590637207 iter = 108\n",
      "loss = 2.216193199157715 iter = 109\n",
      "loss = 2.216184377670288 iter = 110\n",
      "loss = 2.2161755561828613 iter = 111\n",
      "loss = 2.2161667346954346 iter = 112\n",
      "loss = 2.2161576747894287 iter = 113\n",
      "loss = 2.216148853302002 iter = 114\n",
      "loss = 2.2161402702331543 iter = 115\n",
      "loss = 2.2161312103271484 iter = 116\n",
      "loss = 2.216122627258301 iter = 117\n",
      "loss = 2.216113805770874 iter = 118\n",
      "loss = 2.2161049842834473 iter = 119\n",
      "loss = 2.2160959243774414 iter = 120\n",
      "loss = 2.2160873413085938 iter = 121\n",
      "loss = 2.216078519821167 iter = 122\n",
      "loss = 2.216069459915161 iter = 123\n",
      "loss = 2.2160608768463135 iter = 124\n",
      "loss = 2.2160518169403076 iter = 125\n",
      "loss = 2.216042995452881 iter = 126\n",
      "loss = 2.216034173965454 iter = 127\n",
      "loss = 2.2160255908966064 iter = 128\n",
      "loss = 2.2160167694091797 iter = 129\n",
      "loss = 2.216007947921753 iter = 130\n",
      "loss = 2.215999126434326 iter = 131\n",
      "loss = 2.2159900665283203 iter = 132\n",
      "loss = 2.2159812450408936 iter = 133\n",
      "loss = 2.215972900390625 iter = 134\n",
      "loss = 2.215963840484619 iter = 135\n",
      "loss = 2.2159550189971924 iter = 136\n",
      "loss = 2.2159461975097656 iter = 137\n",
      "loss = 2.215937376022339 iter = 138\n",
      "loss = 2.215928554534912 iter = 139\n",
      "loss = 2.2159199714660645 iter = 140\n",
      "loss = 2.2159111499786377 iter = 141\n",
      "loss = 2.21590256690979 iter = 142\n",
      "loss = 2.215893268585205 iter = 143\n",
      "loss = 2.2158849239349365 iter = 144\n",
      "loss = 2.2158758640289307 iter = 145\n",
      "loss = 2.215867280960083 iter = 146\n",
      "loss = 2.215858221054077 iter = 147\n",
      "loss = 2.2158496379852295 iter = 148\n",
      "loss = 2.2158408164978027 iter = 149\n",
      "loss = 2.215831995010376 iter = 150\n",
      "loss = 2.2158234119415283 iter = 151\n",
      "loss = 2.2158145904541016 iter = 152\n",
      "loss = 2.215805768966675 iter = 153\n",
      "loss = 2.215796947479248 iter = 154\n",
      "loss = 2.215787887573242 iter = 155\n",
      "loss = 2.2157795429229736 iter = 156\n",
      "loss = 2.2157704830169678 iter = 157\n",
      "loss = 2.215761661529541 iter = 158\n",
      "loss = 2.2157528400421143 iter = 159\n",
      "loss = 2.2157442569732666 iter = 160\n",
      "loss = 2.21573543548584 iter = 161\n",
      "loss = 2.215726613998413 iter = 162\n",
      "loss = 2.2157180309295654 iter = 163\n",
      "loss = 2.2157092094421387 iter = 164\n",
      "loss = 2.215700149536133 iter = 165\n",
      "loss = 2.2156918048858643 iter = 166\n",
      "loss = 2.2156829833984375 iter = 167\n",
      "loss = 2.2156741619110107 iter = 168\n",
      "loss = 2.215665578842163 iter = 169\n",
      "loss = 2.2156567573547363 iter = 170\n",
      "loss = 2.2156481742858887 iter = 171\n",
      "loss = 2.215639114379883 iter = 172\n",
      "loss = 2.215630531311035 iter = 173\n",
      "loss = 2.2156217098236084 iter = 174\n",
      "loss = 2.2156128883361816 iter = 175\n",
      "loss = 2.215604066848755 iter = 176\n",
      "loss = 2.2155954837799072 iter = 177\n",
      "loss = 2.2155866622924805 iter = 178\n",
      "loss = 2.215578317642212 iter = 179\n",
      "loss = 2.215569019317627 iter = 180\n",
      "loss = 2.2155606746673584 iter = 181\n",
      "loss = 2.2155516147613525 iter = 182\n",
      "loss = 2.215542793273926 iter = 183\n",
      "loss = 2.215534210205078 iter = 184\n",
      "loss = 2.2155253887176514 iter = 185\n",
      "loss = 2.2155165672302246 iter = 186\n",
      "loss = 2.215507984161377 iter = 187\n",
      "loss = 2.2154994010925293 iter = 188\n",
      "loss = 2.2154905796051025 iter = 189\n",
      "loss = 2.215481758117676 iter = 190\n",
      "loss = 2.215473175048828 iter = 191\n",
      "loss = 2.2154643535614014 iter = 192\n",
      "loss = 2.2154557704925537 iter = 193\n",
      "loss = 2.215446949005127 iter = 194\n",
      "loss = 2.2154381275177 iter = 195\n",
      "loss = 2.2154295444488525 iter = 196\n",
      "loss = 2.215420961380005 iter = 197\n",
      "loss = 2.215412139892578 iter = 198\n",
      "loss = 2.2154033184051514 iter = 199\n",
      "loss = 2.2153944969177246 iter = 200\n",
      "loss = 2.215385913848877 iter = 201\n",
      "loss = 2.21537709236145 iter = 202\n",
      "loss = 2.2153685092926025 iter = 203\n",
      "loss = 2.215359926223755 iter = 204\n",
      "loss = 2.215351104736328 iter = 205\n",
      "loss = 2.2153422832489014 iter = 206\n",
      "loss = 2.2153337001800537 iter = 207\n",
      "loss = 2.215325117111206 iter = 208\n",
      "loss = 2.2153162956237793 iter = 209\n",
      "loss = 2.2153077125549316 iter = 210\n",
      "loss = 2.215299367904663 iter = 211\n",
      "loss = 2.215290069580078 iter = 212\n",
      "loss = 2.2152814865112305 iter = 213\n",
      "loss = 2.215272903442383 iter = 214\n",
      "loss = 2.215264081954956 iter = 215\n",
      "loss = 2.2152552604675293 iter = 216\n",
      "loss = 2.2152466773986816 iter = 217\n",
      "loss = 2.215237855911255 iter = 218\n",
      "loss = 2.2152292728424072 iter = 219\n",
      "loss = 2.2152206897735596 iter = 220\n",
      "loss = 2.215211868286133 iter = 221\n",
      "loss = 2.2152035236358643 iter = 222\n",
      "loss = 2.2151944637298584 iter = 223\n",
      "loss = 2.21518611907959 iter = 224\n",
      "loss = 2.215177297592163 iter = 225\n",
      "loss = 2.2151684761047363 iter = 226\n",
      "loss = 2.2151598930358887 iter = 227\n",
      "loss = 2.215151309967041 iter = 228\n",
      "loss = 2.2151427268981934 iter = 229\n",
      "loss = 2.2151339054107666 iter = 230\n",
      "loss = 2.21512508392334 iter = 231\n",
      "loss = 2.2151167392730713 iter = 232\n",
      "loss = 2.2151079177856445 iter = 233\n",
      "loss = 2.215099334716797 iter = 234\n",
      "loss = 2.215090751647949 iter = 235\n",
      "loss = 2.2150819301605225 iter = 236\n",
      "loss = 2.215073347091675 iter = 237\n",
      "loss = 2.215064525604248 iter = 238\n",
      "loss = 2.2150559425354004 iter = 239\n",
      "loss = 2.2150471210479736 iter = 240\n",
      "loss = 2.215038537979126 iter = 241\n",
      "loss = 2.2150299549102783 iter = 242\n",
      "loss = 2.2150213718414307 iter = 243\n",
      "loss = 2.215012550354004 iter = 244\n",
      "loss = 2.215003728866577 iter = 245\n",
      "loss = 2.2149951457977295 iter = 246\n",
      "loss = 2.214986562728882 iter = 247\n",
      "loss = 2.2149782180786133 iter = 248\n",
      "loss = 2.2149696350097656 iter = 249\n",
      "loss = 2.214960813522339 iter = 250\n",
      "loss = 2.214951992034912 iter = 251\n",
      "loss = 2.2149434089660645 iter = 252\n",
      "loss = 2.214934825897217 iter = 253\n",
      "loss = 2.214926242828369 iter = 254\n",
      "loss = 2.2149176597595215 iter = 255\n",
      "loss = 2.2149085998535156 iter = 256\n",
      "loss = 2.214900255203247 iter = 257\n",
      "loss = 2.2148916721343994 iter = 258\n",
      "loss = 2.2148828506469727 iter = 259\n",
      "loss = 2.214874267578125 iter = 260\n",
      "loss = 2.2148659229278564 iter = 261\n",
      "loss = 2.214857339859009 iter = 262\n",
      "loss = 2.214848518371582 iter = 263\n",
      "loss = 2.2148399353027344 iter = 264\n",
      "loss = 2.2148311138153076 iter = 265\n",
      "loss = 2.21482253074646 iter = 266\n",
      "loss = 2.2148141860961914 iter = 267\n",
      "loss = 2.2148053646087646 iter = 268\n",
      "loss = 2.214796543121338 iter = 269\n",
      "loss = 2.2147884368896484 iter = 270\n",
      "loss = 2.2147796154022217 iter = 271\n",
      "loss = 2.214770793914795 iter = 272\n",
      "loss = 2.2147624492645264 iter = 273\n",
      "loss = 2.2147538661956787 iter = 274\n",
      "loss = 2.214745044708252 iter = 275\n",
      "loss = 2.2147364616394043 iter = 276\n",
      "loss = 2.2147278785705566 iter = 277\n",
      "loss = 2.21471905708313 iter = 278\n",
      "loss = 2.2147104740142822 iter = 279\n",
      "loss = 2.2147018909454346 iter = 280\n",
      "loss = 2.214693546295166 iter = 281\n",
      "loss = 2.2146849632263184 iter = 282\n",
      "loss = 2.2146763801574707 iter = 283\n",
      "loss = 2.214667320251465 iter = 284\n",
      "loss = 2.2146589756011963 iter = 285\n",
      "loss = 2.2146506309509277 iter = 286\n",
      "loss = 2.214641809463501 iter = 287\n",
      "loss = 2.2146332263946533 iter = 288\n",
      "loss = 2.2146246433258057 iter = 289\n",
      "loss = 2.214616060256958 iter = 290\n",
      "loss = 2.2146074771881104 iter = 291\n",
      "loss = 2.2145988941192627 iter = 292\n",
      "loss = 2.214590311050415 iter = 293\n",
      "loss = 2.2145814895629883 iter = 294\n",
      "loss = 2.2145731449127197 iter = 295\n",
      "loss = 2.214564561843872 iter = 296\n",
      "loss = 2.2145559787750244 iter = 297\n",
      "loss = 2.2145471572875977 iter = 298\n",
      "loss = 2.214538812637329 iter = 299\n",
      "loss = 2.2145302295684814 iter = 300\n",
      "loss = 2.214521646499634 iter = 301\n",
      "loss = 2.214513063430786 iter = 302\n",
      "loss = 2.2145044803619385 iter = 303\n",
      "loss = 2.2144956588745117 iter = 304\n",
      "loss = 2.214487314224243 iter = 305\n",
      "loss = 2.2144784927368164 iter = 306\n",
      "loss = 2.214470148086548 iter = 307\n",
      "loss = 2.2144618034362793 iter = 308\n",
      "loss = 2.2144529819488525 iter = 309\n",
      "loss = 2.214444398880005 iter = 310\n",
      "loss = 2.2144358158111572 iter = 311\n",
      "loss = 2.2144274711608887 iter = 312\n",
      "loss = 2.214418649673462 iter = 313\n",
      "loss = 2.2144100666046143 iter = 314\n",
      "loss = 2.2144017219543457 iter = 315\n",
      "loss = 2.214393138885498 iter = 316\n",
      "loss = 2.2143845558166504 iter = 317\n",
      "loss = 2.2143759727478027 iter = 318\n",
      "loss = 2.214367389678955 iter = 319\n",
      "loss = 2.2143585681915283 iter = 320\n",
      "loss = 2.214350461959839 iter = 321\n",
      "loss = 2.214341640472412 iter = 322\n",
      "loss = 2.2143330574035645 iter = 323\n",
      "loss = 2.214324474334717 iter = 324\n",
      "loss = 2.214315891265869 iter = 325\n",
      "loss = 2.2143073081970215 iter = 326\n",
      "loss = 2.214298963546753 iter = 327\n",
      "loss = 2.2142903804779053 iter = 328\n",
      "loss = 2.2142817974090576 iter = 329\n",
      "loss = 2.21427321434021 iter = 330\n",
      "loss = 2.2142648696899414 iter = 331\n",
      "loss = 2.2142562866210938 iter = 332\n",
      "loss = 2.214247941970825 iter = 333\n",
      "loss = 2.2142393589019775 iter = 334\n",
      "loss = 2.21423077583313 iter = 335\n",
      "loss = 2.2142221927642822 iter = 336\n",
      "loss = 2.2142138481140137 iter = 337\n",
      "loss = 2.214205265045166 iter = 338\n",
      "loss = 2.2141966819763184 iter = 339\n",
      "loss = 2.2141880989074707 iter = 340\n",
      "loss = 2.214179515838623 iter = 341\n",
      "loss = 2.2141709327697754 iter = 342\n",
      "loss = 2.2141623497009277 iter = 343\n",
      "loss = 2.214154005050659 iter = 344\n",
      "loss = 2.2141454219818115 iter = 345\n",
      "loss = 2.214136838912964 iter = 346\n",
      "loss = 2.2141284942626953 iter = 347\n",
      "loss = 2.2141199111938477 iter = 348\n",
      "loss = 2.214111566543579 iter = 349\n",
      "loss = 2.2141027450561523 iter = 350\n",
      "loss = 2.214094400405884 iter = 351\n",
      "loss = 2.2140860557556152 iter = 352\n",
      "loss = 2.2140774726867676 iter = 353\n",
      "loss = 2.21406888961792 iter = 354\n",
      "loss = 2.2140603065490723 iter = 355\n",
      "loss = 2.2140519618988037 iter = 356\n",
      "loss = 2.214043378829956 iter = 357\n",
      "loss = 2.2140347957611084 iter = 358\n",
      "loss = 2.21402645111084 iter = 359\n",
      "loss = 2.214017868041992 iter = 360\n",
      "loss = 2.2140092849731445 iter = 361\n",
      "loss = 2.214000940322876 iter = 362\n",
      "loss = 2.2139923572540283 iter = 363\n",
      "loss = 2.2139837741851807 iter = 364\n",
      "loss = 2.213975429534912 iter = 365\n",
      "loss = 2.2139668464660645 iter = 366\n",
      "loss = 2.213958263397217 iter = 367\n",
      "loss = 2.2139499187469482 iter = 368\n",
      "loss = 2.2139413356781006 iter = 369\n",
      "loss = 2.213932991027832 iter = 370\n",
      "loss = 2.2139246463775635 iter = 371\n",
      "loss = 2.2139158248901367 iter = 372\n",
      "loss = 2.213907480239868 iter = 373\n",
      "loss = 2.2138986587524414 iter = 374\n",
      "loss = 2.213890552520752 iter = 375\n",
      "loss = 2.2138819694519043 iter = 376\n",
      "loss = 2.2138736248016357 iter = 377\n",
      "loss = 2.213865041732788 iter = 378\n",
      "loss = 2.2138562202453613 iter = 379\n",
      "loss = 2.213848114013672 iter = 380\n",
      "loss = 2.213839530944824 iter = 381\n",
      "loss = 2.2138311862945557 iter = 382\n",
      "loss = 2.213822603225708 iter = 383\n",
      "loss = 2.2138142585754395 iter = 384\n",
      "loss = 2.213805675506592 iter = 385\n",
      "loss = 2.2137973308563232 iter = 386\n",
      "loss = 2.2137887477874756 iter = 387\n",
      "loss = 2.213780403137207 iter = 388\n",
      "loss = 2.2137720584869385 iter = 389\n",
      "loss = 2.21376371383667 iter = 390\n",
      "loss = 2.213754653930664 iter = 391\n",
      "loss = 2.2137463092803955 iter = 392\n",
      "loss = 2.213738203048706 iter = 393\n",
      "loss = 2.2137296199798584 iter = 394\n",
      "loss = 2.21372127532959 iter = 395\n",
      "loss = 2.2137129306793213 iter = 396\n",
      "loss = 2.2137043476104736 iter = 397\n",
      "loss = 2.213696002960205 iter = 398\n",
      "loss = 2.2136871814727783 iter = 399\n",
      "loss = 2.213679075241089 iter = 400\n",
      "loss = 2.2136707305908203 iter = 401\n",
      "loss = 2.2136621475219727 iter = 402\n",
      "loss = 2.213653564453125 iter = 403\n",
      "loss = 2.2136452198028564 iter = 404\n",
      "loss = 2.213636636734009 iter = 405\n",
      "loss = 2.2136282920837402 iter = 406\n",
      "loss = 2.2136197090148926 iter = 407\n",
      "loss = 2.213611364364624 iter = 408\n",
      "loss = 2.2136025428771973 iter = 409\n",
      "loss = 2.213594675064087 iter = 410\n",
      "loss = 2.2135860919952393 iter = 411\n",
      "loss = 2.2135775089263916 iter = 412\n",
      "loss = 2.213569402694702 iter = 413\n",
      "loss = 2.2135608196258545 iter = 414\n",
      "loss = 2.213552236557007 iter = 415\n",
      "loss = 2.2135438919067383 iter = 416\n",
      "loss = 2.2135355472564697 iter = 417\n",
      "loss = 2.213527202606201 iter = 418\n",
      "loss = 2.2135186195373535 iter = 419\n",
      "loss = 2.213510274887085 iter = 420\n",
      "loss = 2.2135016918182373 iter = 421\n",
      "loss = 2.2134933471679688 iter = 422\n",
      "loss = 2.2134850025177 iter = 423\n",
      "loss = 2.2134764194488525 iter = 424\n",
      "loss = 2.213468313217163 iter = 425\n",
      "loss = 2.2134594917297363 iter = 426\n",
      "loss = 2.213451385498047 iter = 427\n",
      "loss = 2.213442802429199 iter = 428\n",
      "loss = 2.2134344577789307 iter = 429\n",
      "loss = 2.213426113128662 iter = 430\n",
      "loss = 2.2134175300598145 iter = 431\n",
      "loss = 2.213409423828125 iter = 432\n",
      "loss = 2.2134008407592773 iter = 433\n",
      "loss = 2.213392496109009 iter = 434\n",
      "loss = 2.2133841514587402 iter = 435\n",
      "loss = 2.2133758068084717 iter = 436\n",
      "loss = 2.213367223739624 iter = 437\n",
      "loss = 2.2133588790893555 iter = 438\n",
      "loss = 2.213350296020508 iter = 439\n",
      "loss = 2.2133421897888184 iter = 440\n",
      "loss = 2.2133336067199707 iter = 441\n",
      "loss = 2.213325262069702 iter = 442\n",
      "loss = 2.2133166790008545 iter = 443\n",
      "loss = 2.213308334350586 iter = 444\n",
      "loss = 2.2132999897003174 iter = 445\n",
      "loss = 2.213291883468628 iter = 446\n",
      "loss = 2.2132833003997803 iter = 447\n",
      "loss = 2.2132749557495117 iter = 448\n",
      "loss = 2.213266372680664 iter = 449\n",
      "loss = 2.2132582664489746 iter = 450\n",
      "loss = 2.213249683380127 iter = 451\n",
      "loss = 2.2132413387298584 iter = 452\n",
      "loss = 2.21323299407959 iter = 453\n",
      "loss = 2.2132248878479004 iter = 454\n",
      "loss = 2.2132163047790527 iter = 455\n",
      "loss = 2.213207960128784 iter = 456\n",
      "loss = 2.2131993770599365 iter = 457\n",
      "loss = 2.213191270828247 iter = 458\n",
      "loss = 2.2131826877593994 iter = 459\n",
      "loss = 2.21317458152771 iter = 460\n",
      "loss = 2.2131659984588623 iter = 461\n",
      "loss = 2.2131576538085938 iter = 462\n",
      "loss = 2.213149309158325 iter = 463\n",
      "loss = 2.2131409645080566 iter = 464\n",
      "loss = 2.213132619857788 iter = 465\n",
      "loss = 2.2131242752075195 iter = 466\n",
      "loss = 2.213115692138672 iter = 467\n",
      "loss = 2.2131075859069824 iter = 468\n",
      "loss = 2.213099241256714 iter = 469\n",
      "loss = 2.2130908966064453 iter = 470\n",
      "loss = 2.2130823135375977 iter = 471\n",
      "loss = 2.2130744457244873 iter = 472\n",
      "loss = 2.2130656242370605 iter = 473\n",
      "loss = 2.213057518005371 iter = 474\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    logits = inp_tr @ W\n",
    "    loss = F.cross_entropy(logits,out_tr)\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    print(f'loss = {loss.item()} iter = {i}')\n",
    "    W.data += -.1 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4324fee-7428-4f1d-913e-c4833953e454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for _ in range(20):\n",
    "  x1,x2 = 0,27\n",
    "  out = '.'\n",
    "  while True:\n",
    "    inp = F.one_hot(torch.tensor([x1]),num_classes=54).float() + F.one_hot(torch.tensor([x2]),num_classes = 54).float()\n",
    "    logits = inp @ W\n",
    "    prob = F.softmax(logits,dim=1) \n",
    "    x1,x2 = x2,torch.multinomial(prob,num_samples = 1,generator = g,replacement=True)\n",
    "    out += itos[x2.item()]\n",
    "    if itos[x2.item()]=='.':\n",
    "      break\n",
    "  print(out)\n",
    "# f.one_hot(torch.tensor([x1]),num_classes=54) + f.one_hot(torch.tensor([x2],num_classes = 54))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
