{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da1b9fb8-7742-4a6c-b3d4-afa3d9439f3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0, 27],\n",
       "         [ 0, 32],\n",
       "         [ 5, 40],\n",
       "         [13, 40],\n",
       "         [13, 28],\n",
       "         [ 0, 27],\n",
       "         [ 0, 42],\n",
       "         [15, 39],\n",
       "         [12, 36],\n",
       "         [ 9, 49]]),\n",
       " tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "words = open(\"names.txt\",'r').read().splitlines()\n",
    "inp = []\n",
    "out = []\n",
    "\n",
    "all_char = sorted(set(\".\".join(words)))\n",
    "stoi = {ch:i for i,ch in enumerate(all_char)}\n",
    "itos = {v:k for k,v in stoi.items()}\n",
    "\n",
    "clen = 2\n",
    "for w in words:\n",
    "    context = '.' * clen\n",
    "    w =  w + '.'\n",
    "    for cur_ch in w:\n",
    "        cur_inp = [stoi[ch] for ch in context]\n",
    "        cur_inp[-1] += 27\n",
    "        inp.append(cur_inp)\n",
    "        out.append(stoi[cur_ch])\n",
    "        context = context[1:] + cur_ch\n",
    "    \n",
    "inp_tri = math.ceil(0.8*len(inp))\n",
    "inp_devi = math.ceil(0.9*len(inp))\n",
    "inp_tr = torch.tensor(inp[0:inp_tri])\n",
    "out_tr = torch.tensor(out[0:inp_tri])\n",
    "inp_dev =torch.tensor(inp[inp_tri:inp_devi])\n",
    "out_dev =torch.tensor(out[inp_tri:inp_devi])\n",
    "inp_tst =torch.tensor(inp[inp_devi:])\n",
    "out_tst =torch.tensor(out[inp_devi:])\n",
    "\n",
    "inp_tr  = F.one_hot(inp_tr,num_classes = 54)\n",
    "inp_tr = inp_tr.sum(dim=1)\n",
    "\n",
    "inp_tr[:10] ,out_tr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "746007e9-1387-48db-a6f1-d822a882c255",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(16)\n",
    "W = torch.randn((54,27),requires_grad = True,generator = g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "937eb4f1-b398-4849-af56-c17f4a287164",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    logits = inp_tr @ W\n",
    "    loss = F.cross_entropy(logits,out_tr)\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    W.data += -1 * W.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
